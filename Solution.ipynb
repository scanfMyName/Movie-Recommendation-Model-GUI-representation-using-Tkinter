{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a06f338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  # disable python warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "import surprise\n",
    "from surprise import Reader, Dataset, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer  # To convert text to numerical data\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "\n",
    "from scipy import sparse\n",
    "import xgboost as xgb\n",
    "from ast import literal_eval  # evaluate strings containing Python code in the current Python environment\n",
    "from nltk.stem.snowball import SnowballStemmer # Removing stem words\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21699eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "ratdf = pd.read_csv('/Users/mayank garg/Desktop/AZHackathon2023/Dataset/ratings_small.csv',  low_memory=False)\n",
    "movdf = pd.read_csv('/Users/mayank garg/Desktop/AZHackathon2023/Dataset/movies_metadata.csv', low_memory=False)\n",
    "keydf =  pd.read_csv('/Users/mayank garg/Desktop/AZHackathon2023/Dataset/keywords.csv', low_memory=False)\n",
    "imdbdf =  pd.read_csv('/Users/mayank garg/Desktop/AZHackathon2023/Dataset/links_small.csv', low_memory=False)\n",
    "castdf =  pd.read_csv('/Users/mayank garg/Desktop/AZHackathon2023/Dataset/credits.csv', low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ratdf.columns)\n",
    "print(keydf.columns)\n",
    "print(castdf.columns)\n",
    "print(imdbdf.columns)\n",
    "print(movdf.columns)\n",
    "movdf.describe()\n",
    "# df.describe()\n",
    "movdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff380952",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(movdf.isnull().sum(), '\\n\\n')\n",
    "print(keydf.isnull().sum(), '\\n\\n')\n",
    "print(imdbdf.isnull().sum(), '\\n\\n')\n",
    "print(castdf.isnull().sum(), '\\n\\n')\n",
    "print(df.isnull().sum(), '\\n\\n')\n",
    "\n",
    "# So there is problem in movdf keydf and imdbdf for the NA thing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79005b99",
   "metadata": {},
   "source": [
    "## Basic Recommendation\n",
    "In general movie recommendation by Imdb rating calculation for all the movies and then the classification is done in two ways:-\n",
    "\n",
    "1. By overall recommendation and \n",
    "2. By genre based recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8400a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "C =  movdf['vote_average'].mean()\n",
    "m =  movdf['vote_count'].quantile(0.95) # How many votes is needed to be in top 5% of the movies having heighest votes\n",
    "# // since we are going to use the vote count and vote_average method for each movie \n",
    "# we need them to be completely filled so we are going to remove them \n",
    "# Similarly we need to remove them from other dataframe also\n",
    "movdf.dropna(subset= ['vote_average', 'vote_count'], inplace = True)\n",
    "movdf.isnull().sum()\n",
    "# How many votes is needed to be in top 5% of the movies having heighest votes\n",
    "top_mov  = movdf.copy().loc[movdf['vote_count'] >= m]  \n",
    "top_mov.reset_index(inplace = True) \n",
    "top_mov['score'] = ''\n",
    "print(C, m)\n",
    "# Now for getting score we will craete a function which will give us the score based on the imdb id\n",
    "# top_mov\n",
    "def getIMDB(cnt, av):\n",
    "#     we already have m and C for the whole dataset now calculating the IMDB score for a particular movie by using its vote\n",
    "#     count(cnt) and vote average(av)\n",
    "    return ((cnt/(cnt+m)) * av) + ((m/(m+cnt)) * C)  \n",
    "\n",
    "for i in range(top_mov.shape[0]):\n",
    "    l = top_mov['vote_count'][i]\n",
    "    g =  top_mov['vote_average'][i]\n",
    "    top_mov['score'][i] =  getIMDB(l, g)\n",
    "\n",
    "top_mov  = top_mov.sort_values(by=['score'], ascending=False)\n",
    "top_mov.reset_index(inplace = True) \n",
    "smpl_recom =  top_mov[['title','score']].head(20)\n",
    "\n",
    "t1 = top_mov[['title', 'score']].head(20)  #Overall recommendation \n",
    "\n",
    "# print(t1)\n",
    "# smpl_recom\n",
    "# top_mov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do plotation\n",
    "# Distribution of average vote among movies in the dataset\n",
    "\n",
    "fig = px.histogram(top_mov, x=\"vote_average\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0657f",
   "metadata": {},
   "source": [
    "### Genre Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af83f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_mov['genres'] = top_mov['genres'].apply(literal_eval)  \n",
    "# Here no need to apply literal_evals they are already in such format as required to be converted by literal_eval\n",
    "# Lets get a list of all the genres may be needed in future for next recommendations\n",
    "\n",
    "genrelist  =  set()\n",
    "genredict  =  dict()\n",
    "\n",
    "#Since we are already have top movies why we need to do them again so we are using them directly here\n",
    "\n",
    "\n",
    "for i in range(top_mov['genres'].shape[0]):\n",
    "    for x in top_mov['genres'][i]:\n",
    "#         print(x)\n",
    "        genrelist.add(x['name'])\n",
    "        \n",
    "for i in range(top_mov['genres'].shape[0]):\n",
    "    for x in top_mov['genres'][i]:\n",
    "#         print(x)\n",
    "        if x['name'] not in genredict.keys():\n",
    "            genredict[x['name']] =  pd.DataFrame(columns = top_mov.columns)\n",
    "        \n",
    "        genredict[x['name']] =  genredict[x['name']].append((top_mov.iloc[i]))\n",
    "        \n",
    "\n",
    "# print(genrelist)\n",
    "genredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940dfa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Plot the everything we have done \n",
    "cntmovgenre  =  list()\n",
    "for i in genrelist:\n",
    "    cntmovgenre.append(genredict[i].shape[0])\n",
    "\n",
    "genrecnt  = pd.DataFrame({'Genre': list(genrelist), 'Movie Counts':cntmovgenre}, columns = ['Genre', 'Movie Counts'])\n",
    "\n",
    "\n",
    "fig =px.bar(genrecnt, x='Genre', y='Movie Counts')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8fdb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genreBasedRecommend(gnr):\n",
    "    if gnr not in genrelist:\n",
    "        return None\n",
    "    return genredict[gnr][['title','score']].head(10)\n",
    "\n",
    "print(genreBasedRecommend('Comedy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207489e6",
   "metadata": {},
   "source": [
    "# Content-Based Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b19fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets do some data preprocessing for generating the final column on which we will do content based filtering\n",
    "\n",
    "movdf['id'] = movdf['id'].astype('int')  #The astype() function is used to cast a pandas object to a specified data type.\n",
    "\n",
    "# merging both credits and keywords in movies_data on the basis of movie id as the primary key\n",
    "movdf = movdf.merge(castdf, on='id')\n",
    "movdf = movdf.merge(keydf, on='id')\n",
    "imdbdf = imdbdf[imdbdf['tmdbId'].notnull()]['tmdbId'].astype('int')\n",
    "smd = movdf[movdf['id'].isin(imdbdf)]  \n",
    "smd = smd.reset_index()\n",
    "\n",
    "smd.head()\n",
    "\n",
    "smd['tagline'] = smd['tagline'].str.split()\n",
    "smd['overview'] = smd['overview'].str.split()\n",
    "\n",
    "# Applying literal_eval to get the right data type from the expression of string\n",
    "smd['cast'] = smd['cast'].apply(literal_eval)\n",
    "smd['crew'] = smd['crew'].apply(literal_eval)\n",
    "smd['keywords'] = smd['keywords'].apply(literal_eval)\n",
    "smd['genres'] = smd['genres'].apply(literal_eval)\n",
    "\n",
    "def get_director(x):\n",
    "    for i in x:\n",
    "        if i['job'] == 'Director':\n",
    "            return i['name']\n",
    "    return np.nan\n",
    "smd['director'] = smd['crew'].apply(get_director) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284da3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Taking all the movie cast in a list and then taking only the top 3 cast\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['cast'] = smd['cast'].apply(lambda x: x[:3] if len(x) >=3 else x)\n",
    "smd['cast'] = smd['cast'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])# Strip Spaces and Convert to Lowercase\n",
    "\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "\n",
    "\n",
    "smd['tagline'] = smd['tagline'].apply(lambda x: [i for i in x] if isinstance(x, list) else [])\n",
    "smd['overview'] = smd['overview'].apply(lambda x: [i for i in x] if isinstance(x, list) else [])\n",
    "\n",
    "smd['genres'] = smd['genres'].apply(lambda x: [i['name'] for i in x] if isinstance(x, list) else [])\n",
    "smd['genres'] = smd['genres'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "smd['director'] = smd['director'].astype('str').apply(lambda x: str.lower(x.replace(\" \", \"\")))\n",
    "smd['director'] = smd['director'].apply(lambda x: [x,x,x]) \n",
    "# giving more weight to the director relative to the entire cast\n",
    "smd['tagline'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a3129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a dictionary which will contain all the keywords for all the movies \n",
    "# with their frequency al over the keyword dataset\n",
    "\n",
    "keywords_count = dict()\n",
    "for i in range(len(smd['keywords'])):\n",
    "    for j in range(len(smd['keywords'][i])):\n",
    "        if smd['keywords'][i][j] not in keywords_count.keys():\n",
    "            keywords_count[smd['keywords'][i][j]] = 0\n",
    "        keywords_count[smd['keywords'][i][j]] +=1\n",
    "\n",
    "# removing those keywords which occur only once\n",
    "for i in list(keywords_count):\n",
    "    if keywords_count[i] == 1:\n",
    "        del keywords_count[i]\n",
    "        \n",
    "        \n",
    "# Generating a dictionary which will contain all the keywords for all the movies \n",
    "# with their frequency al over the keyword dataset\n",
    "\n",
    "overview_count = dict()\n",
    "for i in range(len(smd['overview'])):\n",
    "    for j in range(len(smd['overview'][i])):\n",
    "        if smd['overview'][i][j] not in overview_count.keys():\n",
    "            overview_count[smd['overview'][i][j]] = 0\n",
    "        overview_count[smd['overview'][i][j]] +=1\n",
    "\n",
    "# removing those keywords which occur only once\n",
    "for i in list(overview_count):\n",
    "    if overview_count[i] == 1:\n",
    "        del overview_count[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32233c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By this function we will genearte a list of keywords for a particular movie which are already there in the\n",
    "# keywords_counts dictionary\n",
    "\n",
    "def filter_overviews(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in overview_count.keys():\n",
    "            words.append(i)\n",
    "    return words\n",
    "\n",
    "print(smd['overview'].isnull().sum())\n",
    "print(smd['tagline'].isnull().sum())\n",
    "\n",
    "# By this function we will genearte a list of keywords for a particular movie which are already there in the\n",
    "# keywords_counts dictionary\n",
    "\n",
    "def filter_keywords(x):\n",
    "    words = []\n",
    "    for i in x:\n",
    "        if i in keywords_count.keys():\n",
    "            words.append(i)\n",
    "    return words\n",
    "\n",
    "print(smd['keywords'].isnull().sum())\n",
    "print(smd['tagline'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626d83ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "smd['keywords'] = smd['keywords'].apply(filter_keywords) # removing those keywords which occur only once\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['keywords'] = smd['keywords'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "smd['tagline'] = smd['tagline'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['tagline'] = smd['tagline'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "smd['overview'] = smd['overview'].apply(filter_overviews) # removing those keywords which occur only once\n",
    "smd['overview'] = smd['overview'].apply(lambda x: [stemmer.stem(i) for i in x])\n",
    "smd['overview'] = smd['overview'].apply(lambda x: [str.lower(i.replace(\" \", \"\")) for i in x])\n",
    "\n",
    "# combining keywords, cast, director and genres\n",
    "smd['soup'] = smd['keywords'] + smd['cast'] + smd['director'] + smd['genres'] +smd['tagline'] + smd['overview']\n",
    "smd['soup'] = smd['soup'].apply(lambda x: ' '.join(x))\n",
    "smd['soup'][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33c7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Wordcloud for visualisation of the word which occur frequently in the dataset\n",
    "\n",
    "# Combining all the text contained in smd['soup'] column\n",
    "text = \"\"\n",
    "for i in smd['soup']:\n",
    "    text +=i\n",
    "    \n",
    "word_cloud = WordCloud(collocations = False, background_color = 'white').generate(text)\n",
    "\n",
    "# Display the generated Word Cloud\n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8))\n",
    "plt.imshow(word_cloud)\n",
    "plt.axis(\"off\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968a79ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = CountVectorizer(analyzer='word',ngram_range=(1, 2) ,min_df=0, stop_words='english')\n",
    "count_matrix = count.fit_transform(smd['soup'])\n",
    "\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)\n",
    "# df['Courses'].str.lower()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'].str.lower())  # Creating a mapping between movie and title and index\n",
    "\n",
    "df_cosine=pd.DataFrame(cosine_sim)\n",
    "df_cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b179a948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Heatmap for visualization of correlation between different movies \n",
    "\n",
    "#specify size of heatmap\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "#create seaborn heatmap of only top 100 movies\n",
    "sns.heatmap(cosine_sim[:100,:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f477c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices =  pd.DataFrame(indices)\n",
    "# indices = indices.reset_index(drop = True)\n",
    "# print(indices['forest gump'])\n",
    "# print(indices[0])\n",
    "# indices['forest gump']\n",
    "indices = pd.Series(smd.index, index=smd['title'].str.lower())\n",
    "print(type(indices.index))\n",
    "print(indices)\n",
    "movnamelist = indices.index.tolist()\n",
    "\n",
    "print(type(indices.index))\n",
    "movnamelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d464c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are going to get the recommendations by inputting particular movie\n",
    "\n",
    "\n",
    "def get_recommendations(title):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    This function gives the top 10 movies according to the cosine similarities calculated above along with the movie id\n",
    "    \n",
    "    Parameters: title (string) : Name of the movie present in the smd dataset\n",
    "    \n",
    "    Returns: (list) Top 10 movies along with the movie id\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    idx = indices[title] # movie id corrosponding to the given title \n",
    "    sim_scores = list(enumerate(cosine_sim[idx])) # list of cosine similarity scores value along the given index\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True) # sorting the given scores in ascending order\n",
    "    sim_scores = sim_scores[1:31] # Taking only the top 30 scores\n",
    "    movie_indices = [i[0] for i in sim_scores] # Finding the indices of 30 most similar movies\n",
    "    \n",
    "    return titles.iloc[movie_indices] \n",
    "\n",
    "get_recommendations('The Dark Knight').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4093a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d9396e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8722e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2d8400d",
   "metadata": {},
   "source": [
    "# Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be9d1cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a0b0fc0c66c0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/Users/mayank garg/Desktop/AZHackathon2023/ratings.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timestamp'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data = ratdf\n",
    "print(data)\n",
    "data = data.drop('timestamp',axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8cc698",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.iloc[:int(data.shape[0]*0.80)]\n",
    "test_data=data.iloc[int(data.shape[0]*0.80):]\n",
    "reader = Reader(rating_scale=(1,5))\n",
    "\n",
    "# create the traindata from the dataframe..., It is of dataset format from surprise library..\n",
    "train_data_mf = Dataset.load_from_df(train_data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# build the trainset from traindata..\n",
    "trainset = train_data_mf.build_full_trainset() \n",
    "\n",
    "# create the testdata from the dataframe...\n",
    "test_data_mf = Dataset.load_from_df(test_data[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "# build the testset from testdata..\n",
    "testset = test_data_mf.build_full_trainset() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06656514",
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = SVD(n_factors=100, biased=True, random_state=15, verbose=True)\n",
    "svd.fit(trainset)\n",
    "#getting predictions of trainset\n",
    "train_preds = svd.test(trainset.build_testset())\n",
    "\n",
    "train_pred_mf = np.array([pred.est for pred in train_preds])\n",
    "#getting predictions of trainset\n",
    "test_preds = svd.test(testset.build_testset())\n",
    "\n",
    "test_pred_mf = np.array([pred.est for pred in test_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec87c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_rmse)\n",
    "print(train_mape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139b70ea",
   "metadata": {},
   "source": [
    "### Sparse Matrix Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f849bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sparse' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8f98d78e6f85>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creating a sparse matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m train_sparse_matrix = sparse.csr_matrix((train_data.rating.values, (train_data.userId.values,\n\u001b[0m\u001b[0;32m      3\u001b[0m                                                train_data.movieId.values)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sparse' is not defined"
     ]
    }
   ],
   "source": [
    "# Creating a sparse matrix\n",
    "train_sparse_matrix = sparse.csr_matrix((train_data.rating.values, (train_data.userId.values,\n",
    "                                               train_data.movieId.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8402fa9",
   "metadata": {},
   "source": [
    "## Generating Hand Crafted features for User Movie Interaction Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a05d2b",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ff3a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_averages = dict()\n",
    "# get the global average of ratings in our train set.\n",
    "train_global_average = train_sparse_matrix.sum()/train_sparse_matrix.count_nonzero()\n",
    "train_averages['global'] = train_global_average\n",
    "\n",
    "def get_average_ratings(sparse_matrix, of_users):\n",
    "    # average ratings of user/axes\n",
    "    ax = 1 if of_users else 0 # 1 - User axes,0 - Movie axes\n",
    "\n",
    "    # \".A1\" is for converting Column_Matrix to 1-D numpy array \n",
    "    sum_of_ratings = sparse_matrix.sum(axis=ax).A1\n",
    "    # Boolean matrix of ratings ( whether a user rated that movie or not)\n",
    "    is_rated = sparse_matrix!=0\n",
    "    # no of ratings that each user OR movie..\n",
    "    no_of_ratings = is_rated.sum(axis=ax).A1\n",
    "    \n",
    "    # max_user  and max_movie ids in sparse matrix \n",
    "    u,m = sparse_matrix.shape\n",
    "    # creae a dictonary of users and their average ratigns..\n",
    "    average_ratings = { i : sum_of_ratings[i]/no_of_ratings[i]\n",
    "                                 for i in range(u if of_users else m) \n",
    "                                    if no_of_ratings[i] !=0}\n",
    "\n",
    "    # return that dictionary of average ratings\n",
    "    return average_ratings\n",
    "\n",
    "train_averages['user'] = get_average_ratings(train_sparse_matrix, of_users=True)\n",
    "print('\\nAverage rating of user 10 :',train_averages['user'][10])\n",
    "\n",
    "train_averages['movie'] =  get_average_ratings(train_sparse_matrix, of_users=False)\n",
    "print('\\n AVerage rating of movie 15 :',train_averages['movie'][15])\n",
    "train_averages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4298fca",
   "metadata": {},
   "source": [
    "### Now top most 5 similar users for a movie and top most 5 similar movies for a user for each user - movie pair in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c3ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get users, movies and ratings from our samples train sparse matrix\n",
    "train_users, train_movies, train_ratings = sparse.find(train_sparse_matrix)\n",
    "final_data = pd.DataFrame()\n",
    "count = 0\n",
    "for (user, movie, rating)  in zip(train_users, train_movies, train_ratings):\n",
    "            st = datetime.now()\n",
    "        #     print(user, movie)    \n",
    "            #--------------------- Ratings of \"movie\" by similar users of \"user\" ---------------------\n",
    "            # compute the similar Users of the \"user\"        \n",
    "            user_sim = cosine_similarity(train_sparse_matrix[user], train_sparse_matrix).ravel()\n",
    "            top_sim_users = user_sim.argsort()[::-1][1:] # we are ignoring current user from its similar users.\n",
    "            # get the ratings of most similar users for the current movie\n",
    "            top_ratings = train_sparse_matrix[top_sim_users, movie].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding movie averages to .\n",
    "            top_sim_users_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_users_ratings.extend([train_averages['movie'][movie]]*(5 - len(top_sim_users_ratings)))\n",
    "            \n",
    "            \n",
    "        #     print(top_sim_users_ratings, end=\" \")    \n",
    "            #--------------------- Ratings by \"user\"  to similar movies of \"movie\" ---------------------\n",
    "            # compute the similar movies of the \"movie\"        \n",
    "            movie_sim = cosine_similarity(train_sparse_matrix[:,movie].T, train_sparse_matrix.T).ravel()\n",
    "            top_sim_movies = movie_sim.argsort()[::-1][1:] # we are ignoring 'The movie' from its similar movies .\n",
    "            # get the ratings of most similar movie rated by this user..\n",
    "            top_ratings = train_sparse_matrix[user, top_sim_movies].toarray().ravel()\n",
    "            # we will make it's length \"5\" by adding user averages to.\n",
    "            top_sim_movies_ratings = list(top_ratings[top_ratings != 0][:5])\n",
    "            top_sim_movies_ratings.extend([train_averages['user'][user]]*(5-len(top_sim_movies_ratings))) \n",
    "        #     print(top_sim_movies_ratings, end=\" : -- \")\n",
    "\n",
    "            #-----------------prepare the row to be stores in a file-----------------#\n",
    "            row = list()\n",
    "            row.append(user)\n",
    "            row.append(movie)\n",
    "            # Now add the other features to this data...\n",
    "            row.append(train_averages['global']) # first feature\n",
    "            # next 5 features are similar_users' \"movie\" ratings\n",
    "            row.extend(top_sim_users_ratings)\n",
    "            # next 5 features are \"user\" ratings for similar_movies\n",
    "            row.extend(top_sim_movies_ratings)\n",
    "            # Avg_user rating\n",
    "            row.append(train_averages['user'][user])\n",
    "            # Avg_movie rating\n",
    "            row.append(train_averages['movie'][movie])\n",
    "\n",
    "            # finalley, The actual Rating of this user-movie pair...\n",
    "            row.append(rating)\n",
    "            count = count + 1\n",
    "            final_data = final_data.append([row])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7c8d92",
   "metadata": {},
   "source": [
    "## Creating XGBoost Model for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b99d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_data.columns=['user', 'movie', 'GAvg', 'sur1', 'sur2', 'sur3', 'sur4', 'sur5',\n",
    "            'smr1', 'smr2', 'smr3', 'smr4', 'smr5', 'UAvg', 'MAvg', 'rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06d0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_metrics(y_true, y_pred):\n",
    "    rmse = np.sqrt(np.mean([ (y_true[i] - y_pred[i])**2 for i in range(len(y_pred)) ]))\n",
    "    mape = np.mean(np.abs( (y_true - y_pred)/y_true )) * 100\n",
    "    return rmse, mape\n",
    "\n",
    "# prepare train data\n",
    "x_train = final_data.drop(['user', 'movie','rating'], axis=1)\n",
    "y_train = final_data['rating']\n",
    "\n",
    "# Prepare Test data\n",
    "x_test = final_test_data.drop(['user','movie','rating'], axis=1)\n",
    "y_test = final_test_data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b9b546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize XGBoost model...\n",
    "xgb_model = xgb.XGBRegressor(silent=False, n_jobs=13, random_state=15, n_estimators=100)\n",
    "# dictionaries for storing train and test results\n",
    "train_results = dict()\n",
    "test_results = dict()\n",
    "\n",
    "# fit the model\n",
    "print('Training the model..')\n",
    "start =datetime.now()\n",
    "xgb_model.fit(x_train, y_train, eval_metric = 'rmse')\n",
    "print('Done. Time taken : {}\\n'.format(datetime.now()-start))\n",
    "print('Done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f125e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the trained model, get the predictions....\n",
    "print('Evaluating the model with TRAIN data...')\n",
    "start =datetime.now()\n",
    "y_train_pred = xgb_model.predict(x_train)\n",
    "# get the rmse and mape of train data...\n",
    "rmse_train, mape_train = get_error_metrics(y_train.values, y_train_pred)\n",
    "    \n",
    "# store the results in train_results dictionary..\n",
    "train_results = {'rmse': rmse_train,\n",
    "                    'mape' : mape_train,\n",
    "                    'predictions' : y_train_pred}\n",
    "train_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd88001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "# get the test data predictions and compute rmse and mape\n",
    "print('Evaluating Test data')\n",
    "y_test_pred = xgb_model.predict(x_test) \n",
    "rmse_test, mape_test = get_error_metrics(y_true=y_test.values, y_pred=y_test_pred)\n",
    "# store them in our test results dictionary.\n",
    "test_results = {'rmse': rmse_test,\n",
    "                    'mape' : mape_test,\n",
    "                    'predictions':y_test_pred}\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcd7d5d",
   "metadata": {},
   "source": [
    "# Tkinter GUI Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aba776b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import tkinter.ttk\n",
    "from tkinter import *\n",
    "import tkinter.messagebox\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a6e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instance creation and all \n",
    "\n",
    "# global windx , winy ,frmx ,frmy ,l,invalidname  ,invalidcchoice \n",
    "#some global variables\n",
    "windx = 1000\n",
    "winy =  400\n",
    "frmx =  1000\n",
    "frmy = 400\n",
    "l = [None for i in range(10)]\n",
    "invalidname = [None for i in range(1)]\n",
    "invalidcchoice = [None for i in range(1)]\n",
    "\n",
    "# create root window\n",
    "root = Tk()\n",
    "# root window title and dimension4\n",
    "root.title(\"Movie Recommender System\")\n",
    "\n",
    "# Set geometry (widthxheight)\n",
    "root.geometry(f'{windx}x{winy}')\n",
    "l1 = Label(root, text = \"MOVIE RECOMMENDER SYSTEM\", fg = \"blue\")\n",
    "l1.grid(row = 0,column = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a088091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#logic or function which will run after the commands\n",
    "def hide_all_frame():\n",
    "    basic_rec_frame.grid_forget()\n",
    "    content_based_frame.grid_forget()\n",
    "    collaborative_frame.grid_forget()\n",
    "# Basic recomendation \n",
    "def basic_rec():\n",
    "    hide_all_frame()\n",
    "    basic_rec_frame.grid(row =0, column  =0)\n",
    "    \n",
    "def basic_based():\n",
    "    global windx , winy ,frmx ,frmy ,l,invalidname  ,invalidcchoice \n",
    "    print(t1)\n",
    "    for i in range(10):\n",
    "        if l[i] is not None:\n",
    "            l[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidname[i] is not None:\n",
    "            invalidname[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidcchoice[i] is not None:\n",
    "            invalidcchoice[i].grid_remove()\n",
    "#   we have all the top 20 movies stored in the above t1 just use that and show that\n",
    "    for i in range(min(10,len(t1))):\n",
    "            l[i] = Label(basic_rec_frame ,  text = t1.iloc[i]['title'])\n",
    "            l[i].grid(row = 2+i, column = 5, sticky = W, pady = 5)\n",
    "    \n",
    "def genre_based():\n",
    "    global windx , winy ,frmx ,frmy ,l,invalidname  ,invalidcchoice \n",
    "    event = clicked.get()\n",
    "    for i in range(10):\n",
    "        if l[i] is not None:\n",
    "            l[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidname[i] is not None:\n",
    "            invalidname[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidcchoice[i] is not None:\n",
    "            invalidcchoice[i].grid_remove()\n",
    "    if event == \"Select Genre\":\n",
    "        invalidchoice[0] = Label(basic_rec_frame ,  text = \"Please select a valid choice\")\n",
    "        invalidchoice[0].grid(row = 2, column = 5, sticky = W, pady = 5)\n",
    "    else:\n",
    "        ll = list((genredict[event][['title']].head(10))['title'])\n",
    "        for i in range(min(10,len(ll))):\n",
    "            l[i] = Label(basic_rec_frame ,  text = ll[i])\n",
    "            l[i].grid(row = 2+i, column = 5, sticky = W, pady = 5)\n",
    "    \n",
    "\n",
    "    \n",
    "# Content Based recomendation\n",
    "def content_rec():\n",
    "    hide_all_frame()\n",
    "    content_based_frame.grid(row =0, column  =0)\n",
    "    \n",
    "def content_based():\n",
    "    global windx , winy ,frmx ,frmy ,l,invalidname  ,invalidcchoice \n",
    "    for i in range(10):\n",
    "        if l[i] is not None:\n",
    "            l[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidname[i] is not None:\n",
    "            invalidname[i].grid_remove()\n",
    "    for i in range(1):\n",
    "        if invalidcchoice[i] is not None:\n",
    "            invalidcchoice[i].grid_remove()\n",
    "    movname =  movvalue.get()\n",
    "    if(movname == \"\"):\n",
    "        invalidname =  Label(content_based_frame ,  text = \"Please enter the valid movie name!!\")\n",
    "        invalidname.grid(row = 2, column = 5, sticky = W, pady = 5)\n",
    "    else:\n",
    "        movname = movname.lower()\n",
    "        print(movname)\n",
    "        res = get_recommendations((movname)).head(10)\n",
    "        res.reset_index(inplace = True, drop =  True)\n",
    "        for i in range(min(10,len(res))):\n",
    "            print(res[i])\n",
    "            l[i] = Label(content_based_frame ,  text = res[i])\n",
    "            l[i].grid(row = 2+i, column = 5, sticky = W, pady = 5)\n",
    "    \n",
    "    \n",
    "# Collaborative based\n",
    "def collaborative_rec():\n",
    "    hide_all_frame()\n",
    "    collaborative_frame.grid(row =0, column  =0)\n",
    "    \n",
    "\n",
    "def collaborative_based():\n",
    "        global windx , winy ,frmx ,frmy ,l,invalidname  ,invalidcchoice \n",
    "        for i in range(10):\n",
    "            if l[i] is not None:\n",
    "                l[i].grid_remove()\n",
    "        for i in range(1):\n",
    "            if invalidname[i] is not None:\n",
    "                invalidname[i].grid_remove()\n",
    "        for i in range(1):\n",
    "            if invalidcchoice[i] is not None:\n",
    "                invalidcchoice[i].grid_remove()\n",
    "        rtts = list()\n",
    "        rtts.append(l11.get())\n",
    "        rtts.append(l12.get())\n",
    "        rtts.append(l13.get())\n",
    "        rtts.append(l14.get())\n",
    "        rtts.append(l15.get())\n",
    "        movie_ratings = [int(i) for i in rtts]\n",
    "        print(movie_ratings)\n",
    "        \n",
    "        example = { 'userId' : [99999,99999,99999,99999,99999],\n",
    "           'movieId' : [278, 13,637,122, 11],\n",
    "           'rating'  : movie_ratings,\n",
    "                  }\n",
    "        df = pd.DataFrame(example)\n",
    "        frames = [ratings, df]\n",
    "        result = pd.concat(frames)\n",
    "        \n",
    "        #create dataset from dataframe\n",
    "        data= Dataset.load_from_df(result[columns],reader)\n",
    "\n",
    "        #create trainset\n",
    "        trainset= data.build_full_trainset()\n",
    "\n",
    "        #create testset, here the anti_testset is testset\n",
    "        testset = trainset.build_anti_testset()\n",
    "\n",
    "        cross_validate(model,data, measures=['RMSE','MAE'], cv= 5, verbose= True)\n",
    "        print('Training Done')\n",
    "\n",
    "        #prediction\n",
    "        prediction = model.test(testset)\n",
    "        print(\"prediction done\")\n",
    "        prediction[99999]\n",
    "\n",
    "        # An RMSE value of less than 2 is considered good\n",
    "        #Now Recommend Users top 10 movies based on prediction\n",
    "\n",
    "        \n",
    "        def get_top_n(prediction, n):\n",
    "\n",
    "            # First map the predictions to each user.\n",
    "            print(\"Here1\")\n",
    "            top_n = defaultdict(list)\n",
    "            for uid, iid, true_r, est, _ in prediction:\n",
    "                top_n[uid].append((iid, est))\n",
    "            print(\"Here2\")\n",
    "            # Then sort the predictions for each user and retrieve the n highest ones.\n",
    "            for uid, user_ratings in top_n.items():\n",
    "                user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "                top_n[uid] = user_ratings[:n]\n",
    "            print(\"Here3\")\n",
    "            return top_n\n",
    "        print(\"Here4\")\n",
    "        rcmnd = []\n",
    "        top_n = get_top_n(prediction, n=30)\n",
    "        print(\"Here5\")\n",
    "        for uid, user_ratings in top_n.items():\n",
    "            if uid == 99999:\n",
    "                print(\"Here6\")\n",
    "                for (iid,rating) in user_ratings:\n",
    "                    for i in range(movdf.shape[0]):\n",
    "                        if movdf['id'][i] == iid:\n",
    "                            print(\"Here7\")\n",
    "                            rcmnd.append([movdf['id'][i],movdf['title'][i]])\n",
    "                break\n",
    "    \n",
    "        for i in range(min(10,len(rcmnd))):\n",
    "            l[i] = Label(collaborative_frame ,  text = rcmnd[i][1])\n",
    "            l[i].grid(row = 2+i, column = 5, sticky = W, pady = 5)\n",
    "        print(\"Here8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859f8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "#creating frame for each recomendation type\n",
    "\n",
    "#Basic Recommendation system\n",
    "# We have to be very careful in these system because we need to show the result in the best format \n",
    "basic_rec_frame = LabelFrame(root, width =frmx , height = frmy)\n",
    "l2 = Label(basic_rec_frame, text = \"Click on the button below to show the best recomended movies of all time:\")\n",
    "l2.grid(row = 1,column = 0,sticky = W, pady = 2)\n",
    "button_basic1 = Button(basic_rec_frame, text = \"SUBMIT\" , fg = \"white\",bg = \"green\", command = basic_based)\n",
    "button_basic1.grid(row = 2,column = 1, sticky = S)\n",
    "\n",
    "#defining labels and buttons in this frame\n",
    "options = [\n",
    "    'Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Family',\n",
    " 'Fantasy',\n",
    " 'History',\n",
    " 'Horror',\n",
    " 'Music',\n",
    " 'Mystery',\n",
    " 'Romance',\n",
    " 'Science Fiction',\n",
    " 'TV Movie',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Western'\n",
    "]\n",
    "\n",
    "# adding a label to the basic frame\n",
    "l3 = Label(basic_rec_frame, text = \"Select genre of the movie you want to watch : \")\n",
    "l3.grid(row = 1,column = 0,sticky = W, pady = 2)\n",
    "\n",
    "# datatype of menu text\n",
    "clicked = StringVar()\n",
    "\n",
    "# initial menu text\n",
    "clicked.set( \"Select Genre\" )\n",
    "\n",
    "# Create Dropdown menu\n",
    "drop = OptionMenu( basic_rec_frame , clicked , *options)\n",
    "drop.grid(row = 3,column = 0, sticky = W)\n",
    "# button widget with green color text\n",
    "button = Button(basic_rec_frame, text = \"SUBMIT\" , fg = \"white\",bg = \"green\", command = genre_based)\n",
    "button.grid(row = 9,column = 1, sticky = S)\n",
    "\n",
    "\n",
    "\n",
    "#Content based filtering \n",
    "content_based_frame = LabelFrame(root, width =frmx , height = frmy)\n",
    "l2 = Label(content_based_frame, text = \"Write name of the any one of the following movie\")\n",
    "l2.grid(row = 1, column  = 0)\n",
    "movvalue =  StringVar()\n",
    "moventry =  Entry(content_based_frame, textvariable = movvalue)\n",
    "moventry.grid(row =1, column = 1)\n",
    "button = Button(content_based_frame, text = \"SUBMIT\" , fg = \"white\",bg = \"green\", command = content_based)\n",
    "button.grid(row = 2,column = 1, sticky = S)\n",
    "\n",
    "\n",
    "#Collaborative filtering\n",
    "collaborative_frame = LabelFrame(root, width =frmx , height = frmy)\n",
    "\n",
    "l3 = Label(collaborative_frame, text = \"Rate the following movies\")\n",
    "l3.grid(row = 1,column = 2,sticky = W, pady = 2)\n",
    "\n",
    "# labels for movies name\n",
    "l4 = Label(collaborative_frame, text=\"Movies Name\").grid(row=2, column=2)\n",
    "l5 = Label(collaborative_frame, text=\"the shawshank redemption\").grid(row=3, column=2) # 278\n",
    "l6 = Label(collaborative_frame, text=\"forest gump\").grid(row=4, column=2) # 13\n",
    "l7 = Label(collaborative_frame, text=\"life is beautiful\").grid(row=5, column=2) #637\n",
    "l8 = Label(collaborative_frame, text=\"the lord of the rings: the return of the king\").grid(row=6, column=2) #122\n",
    "l9 = Label(collaborative_frame, text=\"star wars\").grid(row=7, column=2) # 11\n",
    "\n",
    "# label for movies rating\n",
    "l10 = Label(collaborative_frame, text=\"Rate the movie on the scale of 5\").grid(row=2, column=3)\n",
    "l11 = Spinbox(collaborative_frame, from_= 0, to = 5)\n",
    "l11.grid(row=3, column=3)\n",
    "l12 = Spinbox(collaborative_frame, from_= 0, to = 5)\n",
    "l12.grid(row=4, column=3)\n",
    "l13= Spinbox(collaborative_frame, from_= 0, to = 5)\n",
    "l13.grid(row=5, column=3)\n",
    "l14 = Spinbox(collaborative_frame, from_= 0, to = 5)\n",
    "l14.grid(row=6, column=3)\n",
    "l15 = Spinbox(collaborative_frame, from_= 0, to = 5)\n",
    "l15.grid(row=7, column=3)\n",
    "\n",
    "\n",
    "# button widget with green color text\n",
    "button = Button(collaborative_frame, text = \"SUBMIT\" , fg = \"white\",bg = \"green\", command = collaborative_based)\n",
    "button.grid(row = 9,column = 1, sticky = S)\n",
    "\n",
    "\n",
    "\n",
    "#The actual strucutre of the GUI\n",
    "mainmenu = Menu(root)\n",
    "mainmenu.add_command(label=\"Basic\", command = basic_rec)\n",
    "mainmenu.add_command(label=\"Content Based\", command = content_rec)\n",
    "mainmenu.add_command(label=\"Collaborative\", command = collaborative_rec)\n",
    "\n",
    "root.config(menu = mainmenu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mailoop \n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fbe1e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
